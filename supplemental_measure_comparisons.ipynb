{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50180e0",
   "metadata": {},
   "source": [
    "----\n",
    "# Comparing RS to established measures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b748901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from itertools import product\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from numpy import log10\n",
    "import random\n",
    "from math import factorial\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import linregress, gaussian_kde, skew\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cum_dists(n_obs, n_bins, cum=True):\n",
    "    \"\"\"Generate all possible discrete distributions for a given number of \n",
    "        observations distributed across a given number of bins\n",
    "    \"\"\"\n",
    "    \n",
    "    def partitions(n, k):\n",
    "        if k == 1:\n",
    "            yield (n,)\n",
    "        else:\n",
    "            for i in range(n + 1):\n",
    "                for result in partitions(n - i, k - 1):\n",
    "                    yield (i,) + result\n",
    "\n",
    "    for combo in partitions(n_obs, n_bins):\n",
    "        if cum:\n",
    "            cum_dist = [sum(combo[:i + 1]) for i in range(n_bins)]\n",
    "            yield cum_dist\n",
    "        else:\n",
    "            yield combo\n",
    "\n",
    "            \n",
    "def count_pts_within_radius(x, y, radius, scale=0):\n",
    "    \"\"\"Count the number of points within a fixed radius in 2D space\"\"\"\n",
    "    \n",
    "    raw_data = np.array([x, y])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    raw_data = raw_data.transpose()\n",
    "    \n",
    "    # Get unique data points by adding each pair of points to a set\n",
    "    unique_points = set()\n",
    "    for xval, yval in raw_data:\n",
    "        unique_points.add((xval, yval))\n",
    "    \n",
    "    count_data = []\n",
    "    for a, b in unique_points:\n",
    "        if scale == 'sqrt':\n",
    "            num_neighbors = len(x[((sqrt(x) - sqrt(a)) ** 2 +\n",
    "                                   (sqrt(y) - sqrt(b)) ** 2) <= sqrt(radius) ** 2])\n",
    "        else:        \n",
    "            num_neighbors = len(x[((x - a) ** 2 + (y - b) ** 2) <= radius ** 2])\n",
    "        count_data.append((a, b, num_neighbors))\n",
    "    return count_data\n",
    "\n",
    "\n",
    "\n",
    "def plot_color_by_pt_dens(x, y, radius, loglog=0, scale=0, plot_obj=None, point_size=10):\n",
    "    \n",
    "    \"\"\"Plot bivariate relationships with large n using color for point density\n",
    "\n",
    "    Inputs:\n",
    "    x & y -- variables to be plotted\n",
    "    radius -- the linear distance within which to count points as neighbors\n",
    "    scale -- a flag to indicate the use of a scale plot (scale = 1)\n",
    "\n",
    "    The color of each point in the plot is determined by the logarithm (base 10)\n",
    "    of the number of points that occur with a given radius of the focal point,\n",
    "    with hotter colors indicating more points. The number of neighboring points\n",
    "    is determined in linear space regardless of whether a scale plot is\n",
    "    presented.\n",
    "    \"\"\"\n",
    "    \n",
    "    plot_data = count_pts_within_radius(x, y, radius, scale)\n",
    "    sorted_plot_data = np.array(sorted(plot_data, key=lambda point: point[2]))\n",
    "\n",
    "    if plot_obj == None:\n",
    "        plot_obj = plt.axes()\n",
    "        \n",
    "    plot_obj.scatter(sorted_plot_data[:, 0],\n",
    "            sorted_plot_data[:, 1],\n",
    "            facecolors='none',\n",
    "            s = point_size, \n",
    "            edgecolors='0.1', \n",
    "            linewidths=1., \n",
    "            #cmap='Greys'\n",
    "            )\n",
    "    \n",
    "    # plot points\n",
    "    c = np.array(sorted_plot_data[:, 2])**0.25\n",
    "    c = np.max(c) - c\n",
    "    plot_obj.scatter(sorted_plot_data[:, 0],\n",
    "                    sorted_plot_data[:, 1],\n",
    "                    c = c,\n",
    "                    s = point_size, \n",
    "                    edgecolors='k', \n",
    "                    linewidths=0.0, \n",
    "                    cmap='Greys_r',\n",
    "                    #alpha = 0.5,\n",
    "                    )\n",
    "        \n",
    "    return plot_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histogram_intersection(p, q):\n",
    "    \n",
    "    # Calculate histogram intersection\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    \n",
    "    minima = np.minimum(p, q)\n",
    "    hi = np.true_divide(np.sum(minima), np.sum(p))\n",
    "    \n",
    "    if hi > 1 or hi < 0:\n",
    "        print('Error, HI =', hi)\n",
    "        print(p)\n",
    "        print(q)\n",
    "        return\n",
    "    return hi\n",
    "\n",
    "\n",
    "def chi_square_distance(p, q):\n",
    "    \n",
    "    # Calculate chi-square distance\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    \n",
    "    p = np.array(p)/np.sum(p)\n",
    "    q = np.array(q)/np.sum(q)\n",
    "\n",
    "    return np.sum(((p - q)**2 / (p + q))) / 2\n",
    "\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \n",
    "    # Calculate Kullback-Leibler Divergence\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    \n",
    "    # Ensure both lists are numpy arrays with dtype=float\n",
    "    \n",
    "    p = np.array(p, dtype=float)\n",
    "    q = np.array(q, dtype=float)\n",
    "    \n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "    \n",
    "    kl_div = np.sum(p * np.log(p / q))\n",
    "    return kl_div\n",
    "\n",
    "\n",
    "def earth_movers_distance(p, q):\n",
    "    \n",
    "    # Calculate Earth Mover's Distance\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    \n",
    "    # Ensure both lists are numpy arrays with dtype=float\n",
    "    p = np.array(p, dtype=float)\n",
    "    q = np.array(q, dtype=float)\n",
    "\n",
    "    # Normalize the distributions to ensure they sum to 1\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    # Calculate cumulative distributions\n",
    "    P = np.cumsum(p)\n",
    "    Q = np.cumsum(q)\n",
    "\n",
    "    # Calculate the cost matrix\n",
    "    C = np.abs(np.subtract.outer(P, Q))\n",
    "\n",
    "    # Solve the linear sum assignment problem\n",
    "    row_ind, col_ind = linear_sum_assignment(C)\n",
    "\n",
    "    # Calculate the Earth Mover's Distance\n",
    "    emd = C[row_ind, col_ind].sum()\n",
    "\n",
    "    return emd\n",
    "\n",
    "\n",
    "def kolmogorov_smirnov_distance(p, q):\n",
    "    \n",
    "    # Calculate KS distance\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    \n",
    "    # Ensure both lists are numpy arrays with dtype=float\n",
    "    p = np.array(p, dtype=float)\n",
    "    q = np.array(q, dtype=float)\n",
    "\n",
    "    # Normalize the distributions to ensure they sum to 1\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    # Calculate cumulative distributions\n",
    "    P = np.cumsum(p)\n",
    "    Q = np.cumsum(q)\n",
    "\n",
    "    # Calculate the KS distance\n",
    "    ks_distance = np.max(np.abs(P - Q))\n",
    "\n",
    "    return ks_distance\n",
    "\n",
    "\n",
    "def rank_probability_score(p, q):\n",
    "    \n",
    "    # Calculate the ranked probability score\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    \n",
    "    # Ensure both lists are numpy arrays with dtype=float\n",
    "    p = np.array(p, dtype=float)\n",
    "    q = np.array(q, dtype=float)\n",
    "\n",
    "    # Normalize the distributions to ensure they sum to 1\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    # Calculate cumulative distributions\n",
    "    P = np.cumsum(p)\n",
    "    Q = np.cumsum(q)\n",
    "\n",
    "    # Calculate Rank Probability Score\n",
    "    rps = np.sum((P - Q)**2)\n",
    "\n",
    "    return rps\n",
    "\n",
    "\n",
    "def RDS(p, q):\n",
    "    \n",
    "    # Calculate Relative distribution shift\n",
    "    \n",
    "    # q is the reference distribution\n",
    "    # p is the query distribution\n",
    "    p_bins = len(p)\n",
    "    p_obs = sum(p)\n",
    "    \n",
    "    q_bins = len(q)\n",
    "    q_obs = sum(q)\n",
    "    \n",
    "    z_p = (p_bins + 1)/p_bins\n",
    "    p = [sum(p[:ii+1])**(z_p) for ii in range(len(p))]\n",
    "    Sp = np.sum(np.array(p)/(p_obs**z_p)) - 1\n",
    "    Sp = Sp/(p_bins - 1)\n",
    "    \n",
    "    z_q = (q_bins + 1)/q_bins\n",
    "    q = [sum(q[:ii+1])**(z_q) for ii in range(len(q))]\n",
    "    Sq = np.sum(np.array(q)/(q_obs**z_q)) - 1\n",
    "    Sq = Sq/(q_bins - 1)\n",
    "    \n",
    "    return Sq - Sp\n",
    "    \n",
    "    \n",
    "def DS(p):\n",
    "    p_bins = len(p)\n",
    "    p_obs = sum(p)\n",
    "    \n",
    "    z_p = (p_bins + 1)/p_bins\n",
    "    p = [sum(p[:ii+1])**(z_p) for ii in range(len(p))]\n",
    "    Sp = np.sum(np.array(p)/(p_obs**z_p)) - 1\n",
    "    ds = Sp/(p_bins - 1)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13ec5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_distributions(N, n, k, model, **kwargs):\n",
    "    dists = []\n",
    "    while len(dists) < N:\n",
    "        \n",
    "        if model == 'Poisson':\n",
    "            lambda_param = kwargs.get('lambda_p', 5)  # Default lambda value is 5\n",
    "            data = np.random.poisson(lambda_param, n)\n",
    "        \n",
    "        elif model == 'Gaussian':\n",
    "            mean = kwargs.get('mean', 0)  # Default mean is 0\n",
    "            std = kwargs.get('std', 1)  # Default standard deviation is 1\n",
    "            data = np.random.normal(mean, std, n)\n",
    "        \n",
    "        elif model == 'Negative binomial':\n",
    "            r = kwargs.get('r', 1)  # Number of successes\n",
    "            p = kwargs.get('p', 0.5)  # Probability of success in each trial\n",
    "            data = np.random.negative_binomial(r, p, n)\n",
    "        \n",
    "        elif model == 'Lognormal':\n",
    "            mean = kwargs.get('mean', 0)  # Mean of the underlying normal distribution\n",
    "            sigma = kwargs.get('sigma', 1)  # Standard deviation of the underlying normal distribution\n",
    "            data = np.random.lognormal(mean, sigma, n)\n",
    "        \n",
    "        elif model == 'Weibull':\n",
    "            a = kwargs.get('a', 1)  # Shape parameter\n",
    "            data = np.random.weibull(a, n)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "        hist_vals, bins = np.histogram(data, bins=k, density=False)\n",
    "        dists.append(hist_vals.tolist())\n",
    "\n",
    "    return dists\n",
    "\n",
    "N = 10**4\n",
    "models = ['Poisson', 'Gaussian', 'Negative binomial', 'Lognormal', 'Weibull']\n",
    "n_ls = [10, 100, 10, 100, 100, 1000]\n",
    "k_ls = [3, 3, 50, 50, 500, 500]\n",
    "\n",
    "for m in models:\n",
    "    fig = plt.figure(figsize=(13, 14))\n",
    "    \n",
    "    fig_num = 0\n",
    "    for i, n in enumerate(n_ls):\n",
    "        k = k_ls[i]\n",
    "            \n",
    "        dists = generate_distributions(N, n=100, k=5, model=m, lambda_p=5)\n",
    "            \n",
    "        RDS_vals = []\n",
    "        csd = []\n",
    "        ks_dists = []\n",
    "        hist_ints = []\n",
    "        kl_divs = []\n",
    "        em_dists = []\n",
    "        rp_scores = []\n",
    "        d1_ls = []\n",
    "        d2_ls = []\n",
    "\n",
    "        num = 0\n",
    "        start_time_0 = time.time()\n",
    "        while num < N:\n",
    "\n",
    "            d1, d2 = random.sample(dists, 2)\n",
    "\n",
    "            d1_ls.append(d1)\n",
    "            d2_ls.append(d2)\n",
    "\n",
    "            # Relative distributional shift\n",
    "            j = RDS(d1, d2)\n",
    "            RDS_vals.append(j)\n",
    "\n",
    "            # KS distance\n",
    "            j = kolmogorov_smirnov_distance(d1, d2)\n",
    "            ks_dists.append(j)\n",
    "\n",
    "            # Histogram intersection\n",
    "            j = histogram_intersection(d1, d2)\n",
    "            hist_ints.append(1-j)\n",
    "\n",
    "            # chi-square distance\n",
    "            j = chi_square_distance(d1, d2)\n",
    "            csd.append(j)\n",
    "\n",
    "            # KL divergence\n",
    "            j = kl_divergence(d1, d2)\n",
    "            kl_divs.append(j)\n",
    "\n",
    "\n",
    "            # Rank probability score\n",
    "            j = rank_probability_score(d1, d2)\n",
    "            rp_scores.append(j)\n",
    "\n",
    "            # Earth movers distance\n",
    "            j = earth_movers_distance(d1, d2)\n",
    "            em_dists.append(j)\n",
    "\n",
    "            num += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "            \n",
    "        lists = [np.sqrt(csd).tolist(),\n",
    "                     ks_dists, \n",
    "                     hist_ints,\n",
    "                     np.sqrt(kl_divs).tolist(), \n",
    "                     em_dists, \n",
    "                     np.sqrt(rp_scores).tolist(),\n",
    "                     np.abs(RDS_vals),\n",
    "                    ]\n",
    "\n",
    "        labs = [r\"$\\sqrt{CSD}$\",\n",
    "                      'KSD',\n",
    "                      '1-HI',\n",
    "                      r\"$\\sqrt{KLD}$\",\n",
    "                      'EMD',\n",
    "                      r\"$\\sqrt{RPS}$\",\n",
    "                      '|RDS|',\n",
    "                     ]\n",
    "        ind = 1\n",
    "            \n",
    "        X_lists = [ks_dists, \n",
    "                       em_dists, \n",
    "                       np.sqrt(rp_scores).tolist(),\n",
    "                       np.sqrt(csd).tolist(), \n",
    "                       hist_ints, \n",
    "                       np.sqrt(kl_divs).tolist(),\n",
    "                      ]\n",
    "\n",
    "        x_labs = ['Kolmogorov-Smirnov distance',\n",
    "                      'Earth Mover Distance',\n",
    "                      r\"$\\sqrt{RPS}$\",\n",
    "                      r\"$\\sqrt{CSD}$\",\n",
    "                      '1 - Histogram Intersection',\n",
    "                      r\"$\\sqrt{KLD}$\",\n",
    "                      ]\n",
    "            \n",
    "        text_x_vals = [0.02, 0.05, 0.02, \n",
    "                           0.02, 0.02, 0.05]\n",
    "\n",
    "        for i, x_ls in enumerate(X_lists):\n",
    "            fig_num += 1\n",
    "\n",
    "            xv = []\n",
    "            yv = []\n",
    "            ct = 0\n",
    "            for ii, val in enumerate(x_ls):\n",
    "                if val > 0 and val < 10**10:\n",
    "                    xv.append(val)\n",
    "                    yv.append(RDS_vals[ii])\n",
    "\n",
    "            plot_color_by_pt_dens(xv, yv, radius=0.05, loglog=0, plot_obj=plt.subplot(6, 6, fig_num), point_size=10)\n",
    "            slope, intercept, r_val, p_val, std_err = linregress(xv, np.abs(yv))\n",
    "            fitted_vals = slope * np.array(xv) + intercept\n",
    "            s = 'n=' + str(n) + ', k=' + str(k) + ' ' + r'$r^{2}$' + ' = ' + str(round(r_val**2, 2))\n",
    "            plt.title(s, fontsize=8)\n",
    "            plt.xlabel(x_labs[i], fontsize= 8)\n",
    "            plt.ylabel('RDS', fontsize= 8)\n",
    "            plt.tick_params(axis='both', labelsize=6)\n",
    "\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.subplots_adjust(hspace=0.65, wspace=0.55)\n",
    "    plt.savefig('Final_Figs/models_and_nk_combos/SupFig_'+m+'.jpg', bbox_inches='tight', format='jpg', dpi=600)\n",
    "    plt.close()\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07378d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
