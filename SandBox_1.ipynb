{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "8b748901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from itertools import product\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from numpy import log10\n",
    "import random\n",
    "from math import factorial\n",
    "from scipy.stats import linregress, gaussian_kde, skew\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "abecec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cum_dists(n_obs, n_bins, cum=True):\n",
    "    \"\"\"Generate all possible discrete distributions for a given number of \n",
    "        observations distributed across a given number of bins\n",
    "    \"\"\"\n",
    "    \n",
    "    def partitions(n, k):\n",
    "        if k == 1:\n",
    "            yield (n,)\n",
    "        else:\n",
    "            for i in range(n + 1):\n",
    "                for result in partitions(n - i, k - 1):\n",
    "                    yield (i,) + result\n",
    "\n",
    "    for combo in partitions(n_obs, n_bins):\n",
    "        if cum:\n",
    "            cum_dist = [sum(combo[:i + 1]) for i in range(n_bins)]\n",
    "            yield cum_dist\n",
    "        else:\n",
    "            yield combo\n",
    "\n",
    "            \n",
    "def get_P(f):\n",
    "    k = len(f)\n",
    "    n = sum(f)\n",
    "    \n",
    "    # 1. Sum of the normalized cumulative values (frequencies, counts, etc.) -- P, the positional average of mass from right to left\n",
    "    # Basically adding up the discrete cumulative classes and dividing by the max.\n",
    "    pn = [sum(f[:ii+1])/n for ii in range(k)]\n",
    "    P = np.sum(pn)\n",
    "    \n",
    "    # 2. Distance of P from the max discrete class -- D = P - 1\n",
    "    D = P - 1 \n",
    "    \n",
    "    # 3. D as a fraction of the maximum distance scaled between 0 and 1\n",
    "    S = D/(k - 1)\n",
    "    \n",
    "    # 4. P as the positional average of mass from left to right ... based cumulative distribution\n",
    "    P_LtR_1 = k - P + 1\n",
    "    \n",
    "    # 5. P as the positional average of mass from left to right ... based on frequency distribution\n",
    "    #positions = np.arange(1, k + 1)  # 1-based positions\n",
    "    #P_LtR_2 = np.sum(positions * f) / sum(f)\n",
    "    \n",
    "    P_LtR_2 = 0\n",
    "    for i, fi in enumerate(f):\n",
    "        P_LtR_2 += (i + 1)*fi/sum(f)\n",
    "    \n",
    "    return P, D, S, P_LtR_1, P_LtR_2\n",
    "\n",
    "\n",
    "def get_DS(f):\n",
    "    k = len(f)\n",
    "    n = sum(f)\n",
    "    \n",
    "    \n",
    "    #F = [sum(f[:ii+1])/n for ii in range(len(f))]\n",
    "    #DS = (np.sum(np.array(F)/(n)) - 1) / (k - 1)\n",
    "    \n",
    "    DS = 0\n",
    "    for i, fi in enumerate(f):\n",
    "        DS += (i + 1)*fi/sum(f)\n",
    "        \n",
    "    DS = DS + k - 1\n",
    "    \n",
    "    return DS\n",
    "\n",
    "\n",
    "def RDS(p, q):\n",
    "    \n",
    "    rds_p = get_DS(p)\n",
    "    rds_q = get_DS(q)\n",
    "    \n",
    "    return rds_q - rds_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4193f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DS(f):\n",
    "    k = len(f)\n",
    "    n = sum(f)\n",
    "    \n",
    "    \n",
    "    #F = [sum(f[:ii+1])/n for ii in range(len(f))]\n",
    "    #DS = (np.sum(np.array(F)/(n)) - 1) / (k - 1)\n",
    "    \n",
    "    DS = 0\n",
    "    for i, fi in enumerate(f):\n",
    "        DS += (i + 1)*fi/sum(f)\n",
    "        \n",
    "    DS = DS + k - 1\n",
    "    \n",
    "    return DS\n",
    "\n",
    "\n",
    "def RDS(p, q):\n",
    "    \n",
    "    rds_p = get_DS(p)\n",
    "    rds_q = get_DS(q)\n",
    "    \n",
    "    return rds_q - rds_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "cd4b0bf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: (5, 0, 0) | P1 = 1.0 | P2 = 1.0 | scaled P1 = 1.0 | scaled P2 = 1.0\n",
      "f: (4, 1, 0) | P1 = 1.2 | P2 = 1.2 | scaled P1 = 1.054994 | scaled P2 = 1.234918\n",
      "f: (4, 0, 1) | P1 = 1.4 | P2 = 1.4 | scaled P1 = 1.19995 | scaled P2 = 1.469836\n",
      "f: (3, 2, 0) | P1 = 1.4 | P2 = 1.4 | scaled P1 = 1.207771 | scaled P2 = 1.458272\n",
      "f: (3, 1, 1) | P1 = 1.6 | P2 = 1.6 | scaled P1 = 1.266508 | scaled P2 = 1.69319\n",
      "f: (2, 3, 0) | P1 = 1.6 | P2 = 1.6 | scaled P1 = 1.416478 | scaled P2 = 1.666979\n",
      "f: (3, 0, 2) | P1 = 1.8 | P2 = 1.8 | scaled P1 = 1.540792 | scaled P2 = 1.916543\n",
      "f: (1, 4, 0) | P1 = 1.8 | P2 = 1.8 | scaled P1 = 1.67512 | scaled P2 = 1.855044\n",
      "f: (2, 2, 1) | P1 = 1.8 | P2 = 1.8 | scaled P1 = 1.433932 | scaled P2 = 1.901897\n",
      "f: (2, 1, 2) | P1 = 2.0 | P2 = 2.0 | scaled P1 = 1.621997 | scaled P2 = 2.12525\n",
      "f: (1, 3, 1) | P1 = 2.0 | P2 = 2.0 | scaled P1 = 1.66328 | scaled P2 = 2.089962\n",
      "f: (0, 5, 0) | P1 = 2.0 | P2 = 2.0 | scaled P1 = 2.0 | scaled P2 = 2.0\n",
      "f: (1, 2, 2) | P1 = 2.2 | P2 = 2.2 | scaled P1 = 1.810062 | scaled P2 = 2.313316\n",
      "f: (2, 0, 3) | P1 = 2.2 | P2 = 2.2 | scaled P1 = 1.958206 | scaled P2 = 2.333957\n",
      "f: (0, 4, 1) | P1 = 2.2 | P2 = 2.2 | scaled P1 = 1.965032 | scaled P2 = 2.234918\n",
      "f: (0, 3, 2) | P1 = 2.4 | P2 = 2.4 | scaled P1 = 2.08252 | scaled P2 = 2.458272\n",
      "f: (1, 1, 3) | P1 = 2.4 | P2 = 2.4 | scaled P1 = 2.060053 | scaled P2 = 2.522023\n",
      "f: (0, 2, 3) | P1 = 2.6 | P2 = 2.6 | scaled P1 = 2.291227 | scaled P2 = 2.666979\n",
      "f: (1, 0, 4) | P1 = 2.6 | P2 = 2.6 | scaled P1 = 2.440202 | scaled P2 = 2.710088\n",
      "f: (0, 1, 4) | P1 = 2.8 | P2 = 2.8 | scaled P1 = 2.585158 | scaled P2 = 2.855044\n",
      "f: (0, 0, 5) | P1 = 3.0 | P2 = 3.0 | scaled P1 = 3.0 | scaled P2 = 3.0\n",
      "\n",
      "\n",
      "21 members of the feasible set for n and k\n"
     ]
    }
   ],
   "source": [
    "def generate_cum_dists(n_obs, n_bins, cum=True):\n",
    "    \"\"\"Generate all possible discrete distributions for a given number of \n",
    "        observations distributed across a given number of bins\n",
    "    \"\"\"\n",
    "    \n",
    "    def partitions(n, k):\n",
    "        if k == 1:\n",
    "            yield (n,)\n",
    "        else:\n",
    "            for i in range(n + 1):\n",
    "                for result in partitions(n - i, k - 1):\n",
    "                    yield (i,) + result\n",
    "\n",
    "    for combo in partitions(n_obs, n_bins):\n",
    "        if cum:\n",
    "            cum_dist = [sum(combo[:i + 1]) for i in range(n_bins)]\n",
    "            yield cum_dist\n",
    "        else:\n",
    "            yield combo\n",
    "\n",
    "\n",
    "# Generate distributions one at a time and add to a list\n",
    "_set = []\n",
    "for dist in generate_cum_dists(n, k, cum=False):\n",
    "    _set.append(dist)\n",
    "\n",
    "n = 5\n",
    "k = 3\n",
    "\n",
    "P1_ls = []\n",
    "P1_scaled_ls = []\n",
    "P2_ls = []\n",
    "P2_scaled_ls = []\n",
    "\n",
    "for i, f in enumerate(_set):\n",
    "\n",
    "    # Use the frequency distribution\n",
    "    P1_scaled = 0\n",
    "    P1 = 0\n",
    "        \n",
    "    for indx, fi in enumerate(f):\n",
    "        i = indx + 1\n",
    "        \n",
    "        P1 += (i*fi) / sum(f)\n",
    "        \n",
    "        z = 1 + 1/\n",
    "        P1_scaled += i*(fi/sum(f))**z\n",
    "    \n",
    "    P1_ls.append(P1)\n",
    "    P1_scaled_ls.append(P1_scaled)\n",
    "    \n",
    "    # Use the cumulative frequency distribution\n",
    "    z = 1 + 1/n\n",
    "    P2 = [sum(f[:ii+1]) for ii in range(len(f))]\n",
    "    P2 = (np.array(P2)/n)\n",
    "    P2_ls.append(k + 1 - sum(P2)) # P1 should equal P2\n",
    "    \n",
    "    P2 = [sum(f[:ii+1]) for ii in range(len(f))]\n",
    "    P2 = (np.array(P2)/n)**z\n",
    "    P2_scaled_ls.append(k + 1 - sum(P2))\n",
    "    \n",
    "\n",
    "#P1_scaled_ls, P1_ls, P2_scaled_ls, P2_ls, _set = zip(*sorted(zip(P1_scaled_ls, P1_ls, P2_scaled_ls, P2_ls, _set)))\n",
    "P1_ls, P1_scaled_ls, P2_scaled_ls, P2_ls, _set = zip(*sorted(zip(P1_ls, P1_scaled_ls, P2_scaled_ls, P2_ls, _set)))\n",
    "\n",
    "for i, P1 in enumerate(P1_ls):\n",
    "    print('f:', _set[i], '| P1 =', round(P1_ls[i],4), '| P2 =', round(P2_ls[i],4), '| scaled P1 =', round(P1_scaled_ls[i],6),  '| scaled P2 =', round(P2_scaled_ls[i],6))\n",
    "\n",
    "print('\\n')\n",
    "print(len(P1_ls), 'members of the feasible set for n and k')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385170d4",
   "metadata": {},
   "source": [
    "# Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "996bffc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10 k: 5\n",
      "cardinality: 1001 | no. of unique ΣF/n: 60 | no. of unique ΣF^z/n^z: 355 \n",
      "\n",
      "n: 10 k: 5\n",
      "cardinality: 1001 | no. of unique ΣF/n: 60 | no. of unique ΣF^z/n^z: 956 \n",
      "\n",
      "n: 10 k: 5\n",
      "cardinality: 1001 | no. of unique ΣF/n: 60 | no. of unique ΣF^z/n^z: 1001 \n",
      "\n",
      "\n",
      "\n",
      "n: 10 k: 5\n",
      "cardinality: 1001 | no. of unique ΣF/n: 60 | no. of unique ΣF^z/n^z: 1001 \n",
      "\n",
      "n: 10 k: 10\n",
      "cardinality: 92378 | no. of unique ΣF/n: 208 | no. of unique ΣF^z/n^z: 92378 \n",
      "\n",
      "n: 20 k: 10\n",
      "cardinality: 10015005 | no. of unique ΣF/n: 491 | no. of unique ΣF^z/n^z: 10015005 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_obs = 10\n",
    "n_bins = 5\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "   \n",
    "################  TOP ROW  ###########\n",
    "\n",
    "_set = []\n",
    "for dist in generate_cum_dists(n_obs, n_bins, cum=False):\n",
    "    _set.append(dist)\n",
    "\n",
    "plot_num = 1\n",
    "for z in [2, 4, 7]:\n",
    "    \n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    for d in _set:\n",
    "\n",
    "        cd = [sum(d[:i+1]) for i in range(len(d))]\n",
    "        ncd = np.array(cd)/max(cd)\n",
    "        t1.append(sum(ncd))\n",
    "\n",
    "        G = [sum(d[:i+1])**(z) for i in range(len(d))]\n",
    "        G_ = np.array(G)/(n_obs**z)\n",
    "\n",
    "        t2.append(sum(G_))\n",
    "\n",
    "    print('n:', n_obs, 'k:', n_bins)\n",
    "    print('cardinality:', len(t1), '| no. of unique ΣF/n:', \n",
    "          len(list(set(t1))), '| no. of unique ΣF^z/n^z:', len(list(set(t2))), '\\n')\n",
    "\n",
    "    ax = plt.subplot(2, 3, plot_num)\n",
    "    plt.scatter(t1, t2, s=1, c='k')\n",
    "    plt.xlabel(r'$\\sum{F/n}$', fontsize= 10)\n",
    "    plt.ylabel(r'$\\sum{F^{' + str(z) + '}/n^{' + str(z) + '}}$', fontsize= 10)\n",
    "    \n",
    "    s = '|A' + r'$_{n' + '=' + str(n_obs) + ', ' + 'k' + '=' + str(n_bins) + '}$' + '| = ' + str(len(_set)) + '\\n'\n",
    "    s += 'Values of ' + r'$\\sum{F^{' + str(z) + '}/n^{' + str(z) + '}}$' + '\\n = ' + str(len(list(set(t2))))\n",
    "    \n",
    "    plt.text(1.01, 3.65, s, fontsize=7)\n",
    "    plt.tick_params(axis='both', labelsize=7)\n",
    "    plot_num += 1\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "################  BOTTOM ROW  ###########  \n",
    "\n",
    "N_obs = [10, 10, 20]\n",
    "N_bins = [5, 10, 10]\n",
    "#N_obs = [10, 10, 10]\n",
    "#N_bins = [5, 5, 5]\n",
    "sets = []\n",
    "for i, n_obs in enumerate(N_obs):\n",
    "    n_bins = N_bins[i]\n",
    "    \n",
    "    _set = []\n",
    "    for dist in generate_cum_dists(n_obs, n_bins, cum=False):\n",
    "        _set.append(dist)\n",
    "    sets.append(_set)\n",
    "\n",
    "\n",
    "for i, n_obs in enumerate(N_obs):\n",
    "    n_bins = N_bins[i]\n",
    "    \n",
    "    _set = sets[i]\n",
    "    \n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    for d in _set:\n",
    "\n",
    "        cd = [sum(d[:ii+1]) for ii in range(len(d))]\n",
    "        ncd = np.array(cd)/max(cd)\n",
    "        t1.append(sum(ncd))\n",
    "\n",
    "        z = 1 + 1/n_obs #(n_bins + 1)/n_bins\n",
    "        G = [sum(d[:ii+1])**(z) for ii in range(len(d))]\n",
    "        G_ = np.array(G)/(n_obs**z)\n",
    "        t2.append(sum(G_))\n",
    "\n",
    "    print('n:', n_obs, 'k:', n_bins)\n",
    "    print('cardinality:', len(t1), '| no. of unique ΣF/n:', \n",
    "          len(list(set(t1))), '| no. of unique ΣF^z/n^z:', len(list(set(t2))), '\\n')\n",
    "    \n",
    "    s = '|A' + r'$_{n' + '=' + str(n_obs) + ', ' + 'k' + '=' + str(n_bins) + '}$' + '| = ' + str(len(_set)) + '\\n'\n",
    "    s += 'Values of ' + r'$\\sum{F^{' + str(z) + '}/n^{' + str(z) + '}}$' + '\\n = ' + str(len(_set))\n",
    "    \n",
    "    if len(_set) > 10**5: \n",
    "        indices = np.random.choice(len(_set), 10**5, replace=False)\n",
    "        t1 = np.array(t1)\n",
    "        t2 = np.array(t2)\n",
    "        t1 = t1[indices]\n",
    "        t2 = t2[indices]\n",
    "        t1 = t1.tolist()\n",
    "        t2 = t2.tolist()\n",
    "    \n",
    "    ax = plt.subplot(2, 3, plot_num)\n",
    "    plt.scatter(t1, t2, s=1, c='k')\n",
    "    plt.xlabel(r'$\\sum{F/n}$', fontsize= 10)\n",
    "    plt.ylabel(r'$\\sum{F^{' + str(z) + '}/n^{' + str(z) + '}}$', fontsize= 10)\n",
    "    \n",
    "    if plot_num == 4:\n",
    "        plt.text(1. * min(t1), 0.73*max(t2), s, fontsize=7)\n",
    "    elif plot_num == 5:\n",
    "        plt.text(1. * min(t1), 0.7*max(t2), s, fontsize=7)\n",
    "    elif plot_num == 6:\n",
    "        plt.text(0.9 * min(t1), 0.74*max(t2), s, fontsize=7)\n",
    "        \n",
    "    plt.tick_params(axis='both', labelsize=7)\n",
    "    plot_num += 1\n",
    "    \n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.subplots_adjust(hspace=0.45, wspace=0.4)\n",
    "plt.savefig('Final_Figs/manuscript/Fig1.pdf', bbox_inches='tight', format='pdf', dpi=600)\n",
    "plt.savefig('Final_Figs/manuscript/Fig1.jpg', bbox_inches='tight', format='jpg', dpi=600)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
