{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702233db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import timeit\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6234e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Video parameters\n",
    "width, height = 300, 300\n",
    "num_frames = 100\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'mp4v' for .mp4 format\n",
    "out = cv2.VideoWriter('data/time_lapse_video/synthetic_video_no_noise_no_bars.mp4', fourcc, 20.0, (width, height))\n",
    "\n",
    "# Define the large stationary ball parameters\n",
    "ball_radius = 100\n",
    "center_x, center_y = 150, 150\n",
    "\n",
    "# Define the frames for the \"blip-out\" periods (the ball should not be drawn during these frames)\n",
    "blip_start_frame1 = 9\n",
    "blip_end_frame1   = 10\n",
    "\n",
    "blip_start_frame2 = 19\n",
    "blip_end_frame2   = 20\n",
    "\n",
    "blip_start_frame3 = 29\n",
    "blip_end_frame3   = 30\n",
    "\n",
    "blip_start_frame4 = 39\n",
    "blip_end_frame4   = 40\n",
    "\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    # Create a blank frame (background)\n",
    "    frame = np.full((height, width, 3), (0, 0, 0), dtype=np.uint8)\n",
    "\n",
    "    # Calculate the hue value to cycle from 0 to 360 degrees,\n",
    "    # then mirror it so that it transitions from 0 to 180 and back to 0.\n",
    "    hue_value = int((frame_idx / num_frames) * 360) % 180\n",
    "    #if hue_value > 180:\n",
    "    #    hue_value = 360 - hue_value\n",
    "\n",
    "    # Create an HSV color and convert it to BGR\n",
    "    ball_color_hsv = np.array([[[hue_value, 255, 255]]], dtype=np.uint8)\n",
    "    ball_color_bgr = cv2.cvtColor(ball_color_hsv, cv2.COLOR_HSV2BGR)[0][0]\n",
    "    ball_color_tuple = tuple(int(c) for c in ball_color_bgr)\n",
    "\n",
    "    # Only draw the ball if the current frame is not within any blip-out interval.\n",
    "    if not ((blip_start_frame1 <= frame_idx < blip_end_frame1) or \n",
    "            (blip_start_frame2 <= frame_idx < blip_end_frame2) or \n",
    "            (blip_start_frame3 <= frame_idx < blip_end_frame3) or \n",
    "            (blip_start_frame4 <= frame_idx < blip_end_frame4)):\n",
    "        cv2.circle(frame, (center_x, center_y), ball_radius, ball_color_tuple, -1)\n",
    "\n",
    "    # Generate base random noise for the frame (general noise)\n",
    "    #base_noise = np.random.normal(0, 0.1, (height, width, 3)).astype(np.uint8)\n",
    "\n",
    "    # Create horizontal noise bars\n",
    "    #bar_height = np.random.randint(10, 20)  # Height of each noise band\n",
    "    #shift_speed = 3  # Vertical shift speed (pixels per frame)\n",
    "    #shift_position = (frame_idx * shift_speed) % height  # Calculate shifting position\n",
    "\n",
    "    # Generate bar noise with stronger intensity\n",
    "    #bar_noise = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    #for y in range(shift_position, height, bar_height * 2):  # Skip space between bars\n",
    "    #    bar_noise_end = min(y + bar_height, height)\n",
    "    #    bar_noise[y:bar_noise_end] = np.random.normal(0, 10, (bar_noise_end - y, width, 3)).astype(np.uint8)\n",
    "\n",
    "    # Combine base noise with bar noise and add to the frame\n",
    "    #combined_noise = cv2.add(base_noise, bar_noise)\n",
    "    #frame = cv2.add(frame, combined_noise)\n",
    "\n",
    "    # Write the frame to the video file\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the video writer object and clean up\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca0ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_histogram(image, num_bins, htype='hue'):\n",
    "    \n",
    "    if htype == 'color':\n",
    "        \"\"\"\n",
    "        Construct a flattened 1D histogram for a color image by concatenating the histograms\n",
    "        of each RGB channel.\n",
    "        \"\"\"\n",
    "        if len(image.shape) == 3:  # Color image (RGB)\n",
    "            channels = cv2.split(image)\n",
    "            histograms = [np.histogram(chan, bins=num_bins, range=(0, 256))[0] for chan in channels]\n",
    "            histogram = np.concatenate(histograms)\n",
    "        else:  # Grayscale image\n",
    "            histogram, _ = np.histogram(image, bins=num_bins, range=(0, 256))\n",
    "        \n",
    "        return histogram\n",
    "    \n",
    "    elif htype == 'hue':\n",
    "        \"\"\"\n",
    "        Construct a 1D hue histogram by converting the image to HSV and calculating the\n",
    "        histogram of the hue channel.\n",
    "        \"\"\"\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        hue_channel = hsv_image[:, :, 0]  # Hue ranges from 0 to 179 in OpenCV\n",
    "\n",
    "        histogram, _ = np.histogram(hue_channel, bins=num_bins, range=(0, 180))\n",
    "        return histogram\n",
    "    \n",
    "    elif htype == 'intensity':\n",
    "        \"\"\"\n",
    "        Construct a 1D intensity histogram by converting the image to grayscale.\n",
    "        \"\"\"\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "        histogram, _ = np.histogram(grayscale_image, bins=num_bins, range=(0, 256))\n",
    "        return histogram\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported histogram type: {htype}\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6cf011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def S_from_bins(f, min_, max_):\n",
    "    \n",
    "    T = 0\n",
    "    i_ls = list(range(min_, max_ + 1))\n",
    "    for i, ival in enumerate(i_ls):\n",
    "        T += ival * f[i]\n",
    "        \n",
    "    T = T/sum(f)\n",
    "    S = (max_ - T)/(max_ - min_)\n",
    "    return S\n",
    "\n",
    "\n",
    "def DS_from_bins(f1, f2, min1, max1, min2, max2):\n",
    "\n",
    "    T1 = 0\n",
    "    i_ls = list(range(min1, max1 + 1))\n",
    "    for i, ix in enumerate(i_ls):\n",
    "        T1 += ix * f1[i]\n",
    "        \n",
    "    T1 = T1/sum(f1)\n",
    "    S1 = (max1 - T1)/(max1 - min1)\n",
    "    \n",
    "    \n",
    "    T2 = 0\n",
    "    i_ls = list(range(min2, max2 + 1))\n",
    "    for i, ix in enumerate(i_ls):\n",
    "        T2 += ix * f2[i]\n",
    "        \n",
    "    T2 = T2/sum(f2)\n",
    "    S2 = (max2 - T2)/(max2 - min2)\n",
    "    \n",
    "    return S1 - S2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a11e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing synthetic_video_no_noise_no_bars...\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "typ = 'intensity'\n",
    "\n",
    "def process_video(video_path, num_bins, return_frames):\n",
    "    \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    metrics = {'DS': [], 'S': [], 'WD': []}\n",
    "    frame_indices = []\n",
    "    first_frame = None\n",
    "    max_ds_value = None\n",
    "    max_ds_frame = None\n",
    "\n",
    "    start_index = 0\n",
    "    end_index = total_frames\n",
    "\n",
    "    reference_hist = None\n",
    "    for frame_count in range(total_frames):\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        if frame_count < start_index or frame_count >= end_index:\n",
    "            continue\n",
    "        if frame_count == start_index:\n",
    "            reference_hist = flatten_histogram(frame, num_bins, typ)\n",
    "            first_frame = frame\n",
    "        \n",
    "        frame_hist = flatten_histogram(frame, num_bins, typ)\n",
    "        \n",
    "        # Expand histograms into sample data\n",
    "        x1 = np.repeat(np.arange(len(frame_hist)), frame_hist)\n",
    "        x2 = np.repeat(np.arange(len(reference_hist)), reference_hist)\n",
    "        \n",
    "        bin_positions = np.arange(1, len(frame_hist) + 1)  # Positions of bins (1-based)\n",
    "        WD_v = stats.wasserstein_distance(bin_positions, bin_positions, u_weights=frame_hist, v_weights=reference_hist)\n",
    "        \n",
    "        DS_v = DS_from_bins(frame_hist, reference_hist, 0, len(frame_hist)-1, 0, len(reference_hist)-1)\n",
    "        S_v = S_from_bins(frame_hist, 0, len(frame_hist)-1)\n",
    "        \n",
    "        metrics['DS'].append(DS_v)\n",
    "        metrics['S'].append(S_v)\n",
    "        metrics['WD'].append(WD_v)\n",
    "                            \n",
    "        ds_value = metrics['DS'][-1]\n",
    "        if max_ds_value is None or abs(ds_value) > abs(max_ds_value):\n",
    "            max_ds_value = ds_value\n",
    "            max_ds_frame = frame\n",
    "        \n",
    "        frame_indices.append(frame_count)\n",
    "\n",
    "    video.release()\n",
    "    if return_frames:\n",
    "        return metrics, frame_indices, first_frame, max_ds_frame, max_ds_value\n",
    "    else:\n",
    "        return metrics, frame_indices\n",
    "\n",
    "    \n",
    "\n",
    "def make_fig(inputs, lab, first_frame, max_ds_frame, max_ds_value):\n",
    "    \n",
    "    fs = 20\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    gs = gridspec.GridSpec(nrows=3, ncols=1, height_ratios=[0.2, 0.4, 0.4])\n",
    "    \n",
    "    # ---------------------\n",
    "    # Row 0: Frame images\n",
    "    # ---------------------\n",
    "    # Define the time points at which to grab frames.\n",
    "    \n",
    "    time_points = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99]\n",
    "    \n",
    "    video_path = f'data/time_lapse_video/{lab}.mp4'\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frames_at_time_points = []\n",
    "    for point in time_points:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, point)\n",
    "        success, frame = video.read()\n",
    "        if success:\n",
    "            frames_at_time_points.append(frame)\n",
    "    video.release()\n",
    "    \n",
    "    resized_frames = [cv2.resize(frame, (80, 80)) for frame in frames_at_time_points]\n",
    "    \n",
    "    # Create a sub-Gridspec in row 0 with one row and as many columns as frames.\n",
    "    gs_images = gs[0].subgridspec(1, len(resized_frames))\n",
    "    for i, frame in enumerate(resized_frames):\n",
    "        ax_img = fig.add_subplot(gs_images[0, i])\n",
    "        ax_img.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax_img.set_title(f'{time_points[i]}', fontsize=fs-4)\n",
    "        ax_img.axis('off')\n",
    "    \n",
    "    wd = inputs[2][0]\n",
    "    s = inputs[0][0]\n",
    "    sd = inputs[1][0]\n",
    "    sd_abs = np.abs(sd)\n",
    "    frames = inputs[1][1]\n",
    "    \n",
    "    # ---------------------\n",
    "    # Row 1: Top plot\n",
    "    # ---------------------\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    \n",
    "    ax.plot(frames, wd, color='k')\n",
    "    ax.set_ylabel('Wasserstein Distance', fontsize=fs-2, c='k')\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.plot(frames, sd_abs, color='k')\n",
    "    ax_twin.set_ylabel(r\"$|Δ\\mathcal{S}|$\", fontsize=fs, c='k')\n",
    "    ax_twin.tick_params(axis='both', labelsize=12)\n",
    "    ax_twin.set_xlim(-4, 104)    \n",
    "    \n",
    "    \n",
    "    # ---------------------\n",
    "    # Row 2: Bottom plot\n",
    "    # ---------------------\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    ax.plot(frames, sd, color='k')\n",
    "    ax.set_ylabel(r\"Δ$\\mathcal{S}$\", fontsize=fs, c='k')\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.plot(frames, s, color='k')\n",
    "    ax_twin.set_ylabel(r\"$\\mathcal{S}$\", fontsize=fs, c='k')\n",
    "    ax_twin.tick_params(axis='both', labelsize=12)\n",
    "    ax_twin.set_xlim(-4, 104)\n",
    "    ax.set_xlabel('Frame', fontsize=fs)\n",
    "    \n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.15)\n",
    "    plt.savefig(f'Final_Figs/manuscript/Fig6_{lab}_'+typ+'.pdf', bbox_inches='tight', format='pdf', dpi=600)\n",
    "    plt.savefig(f'Final_Figs/manuscript/Fig6_{lab}_'+typ+'.png', bbox_inches='tight', dpi=600)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "# ---------------------\n",
    "# Run the analysis for each video\n",
    "# ---------------------\n",
    "\n",
    "#lists = [['synthetic_video_with_noise_and_bars']]\n",
    "#lists = [['synthetic_video_no_noise_no_bars_no_spikes']]\n",
    "lists = [['synthetic_video_no_noise_no_bars']]\n",
    "\n",
    "\n",
    "for ls in lists:\n",
    "    lab = ls[0]\n",
    "    video_path = f'data/time_lapse_video/{lab}.mp4'\n",
    "    if os.path.exists(f'Final_Figs/from_image_analysis/{lab}_enhanced.pdf'):\n",
    "        print('Already exists:', lab)\n",
    "    else:\n",
    "        print(f'Processing {lab}...')\n",
    "    \n",
    "    num_bins = 256\n",
    "    metrics, frame_indices, first_frame, max_ds_frame, max_ds_value = process_video(\n",
    "        video_path, num_bins, return_frames=True\n",
    "    )\n",
    "    \n",
    "    inputs = [\n",
    "        [metrics['S'], frame_indices, 'S'],\n",
    "        [metrics['DS'], frame_indices, 'DS'],\n",
    "        [metrics['WD'], frame_indices, 'WD'],\n",
    "    ]\n",
    "    \n",
    "    make_fig(inputs, lab, first_frame, max_ds_frame, max_ds_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537ef4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
